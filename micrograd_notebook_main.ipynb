{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30684,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import math\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\n%matplotlib inline\n\n\nprint('import success')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-04T16:57:07.451076Z","iopub.execute_input":"2024-05-04T16:57:07.451456Z","iopub.status.idle":"2024-05-04T16:57:07.489317Z","shell.execute_reply.started":"2024-05-04T16:57:07.451423Z","shell.execute_reply":"2024-05-04T16:57:07.488212Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"import success\n","output_type":"stream"}]},{"cell_type":"code","source":"class Value:\n    \n    def __init__(self,data, _children=(), _op='', label=''):\n        self.data = data\n        self._prev = set(_children)\n        self._op = _op\n        self.label = label\n        self.grad = 0.0\n        self._backward = lambda: None\n        \n    def __repr__(self):\n        return f\"Value(data={self.data})\"\n    \n    def __add__(self,other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data + other.data, (self, other), '+')\n        \n        def _backward():\n            self.grad += 1.0 * out.grad\n            other.grad += 1.0 * out.grad\n        out._backward = _backward\n        \n        \n        return out\n    \n    def __mul__(self,other):\n        other = other if isinstance(other, Value) else Value(other)\n        out = Value(self.data * other.data, (self, other), '*')\n        \n        def _backward():\n            self.grad += other.data * out.grad\n            other.grad += self.data * out.grad\n        out._backward = _backward\n        return out\n    \n    \n    \n    def __pow__(self, other):\n        assert isinstance(other, (int, float)), \"supports only integer/float powers for now\"\n        out = Value(self.data**other, (self,), f'**{other}')\n        \n        def _backward():\n            self.grad += other * (self.data ** (other - 1)) * out.grad\n        out._backward = _backward\n        \n        return out\n            \n              \n    \n    def __rmul__(self, other):\n        return self*other\n    \n    def __truediv__(self, other): # self / other\n        return self * other**-1\n    \n    def __neg__(self):   # negation i.e -self\n        return self * -1\n    \n    def __sub__(self, other):\n        return self + (-other)\n    \n    \n    def tanh(self):\n        x = self.data\n        t = (math.exp(2*x) - 1)/(math.exp(2*x) + 1)\n        out = Value(t, (self, ), 'tanh')\n        \n        def _backward():\n            self.grad += (1 - t**2) * out.grad\n            \n        out._backward = _backward\n            \n        \n        return out\n    \n    def exp(self):\n        x = self.data\n        out = Value(math.exp(x), (self, ), 'exp')\n        \n        \n        def _backward():\n            self.grad += out.data * out.grad\n        out._backward = _backward\n        \n        return out\n    \n\n    \n    def backward(self):\n        topo = []\n        visited = set()\n        def build_topo(v):\n            if v not in visited:\n                visited.add(v)\n                for child in v._prev:\n                    build_topo(child)\n                topo.append(v)\n        build_topo(self)\n            \n        self.grad = 1.0\n        for node in reversed(topo):\n            node._backward()\n\n\n    \n    \nprint('success')","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:57:12.775126Z","iopub.execute_input":"2024-05-04T16:57:12.775538Z","iopub.status.idle":"2024-05-04T16:57:12.793107Z","shell.execute_reply.started":"2024-05-04T16:57:12.775503Z","shell.execute_reply":"2024-05-04T16:57:12.792016Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"success\n","output_type":"stream"}]},{"cell_type":"code","source":"from graphviz import Digraph\n\ndef trace(root):\n    nodes, edges = set(), set()\n    def build(v):\n        if v not in nodes:\n            nodes.add(v)\n            for child in v._prev:\n                edges.add((child,v))\n                build(child)\n    build(root)\n    return nodes, edges\n\ndef draw_dot(root):\n    dot = Digraph(format='svg', graph_attr={'rankdir': 'LR'})\n    \n    nodes, edges = trace(root)\n    for n in nodes:\n        uid = str(id(n))\n        dot.node(name = uid, label = \"{ %s | data %.4f | grad %.4f}\"% (n.label, n.data, n.grad), shape='record')\n        if n._op:\n            dot.node(name = uid + n._op, label = n._op)\n            dot.edge(uid + n._op, uid)\n            \n    for n1, n2 in edges:\n        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n        \n    return dot\n\n\nprint('success')","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:57:21.743560Z","iopub.execute_input":"2024-05-04T16:57:21.744460Z","iopub.status.idle":"2024-05-04T16:57:21.791696Z","shell.execute_reply.started":"2024-05-04T16:57:21.744425Z","shell.execute_reply":"2024-05-04T16:57:21.790456Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"success\n","output_type":"stream"}]},{"cell_type":"code","source":"###tanh as whole \n## inputs x1,x1\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n\n## weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n\n## bias b\nb = Value(6.8813735870195432, label='b')\n\n## x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\no = n.tanh(); o.label = 'o'\no.backward()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#draw_dot(o)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###tanh broken\n## inputs x1,x1\nx1 = Value(2.0, label='x1')\nx2 = Value(0.0, label='x2')\n\n## weights w1,w2\nw1 = Value(-3.0, label='w1')\nw2 = Value(1.0, label='w2')\n\n## bias b\nb = Value(6.8813735870195432, label='b')\n\n## x1*w1 + x2*w2 + b\nx1w1 = x1*w1; x1w1.label = 'x1*w1'\nx2w2 = x2*w2; x2w2.label = 'x2*w2'\nx1w1x2w2 = x1w1 + x2w2; x1w1x2w2.label = 'x1*w1 + x2*w2'\nn = x1w1x2w2 + b; n.label = 'n'\n# -----\ne = (2*n).exp()\no = (e-1)/(e+1) \n# -----\no.label = 'o'\no.backward()\ndraw_dot(o)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nx1 = torch.Tensor([2.0]).double()                     ; x1.requires_grad = True\nx2 = torch.Tensor([0.0]).double()                     ; x2.requires_grad = True\nw1 = torch.Tensor([-3.0]).double()                    ; w1.requires_grad = True\nw2 = torch.Tensor([1.0]).double()                     ; w2.requires_grad = True\nb = torch.Tensor([6.8813735870195432]).double()       ; b.requires_grad = True\nn = x1*w1 + x2*w2 + b\no = torch.tanh(n)\n\nprint(o.data.item())\no.backward()\n\nprint('___')\nprint('x2', x2.grad.item())\nprint('w2', w2.grad.item())\nprint('x1', x1.grad.item())\nprint('w1', w1.grad.item())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"o.data.item()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##need to import random first\n\nclass Neuron:\n    \n    def __init__(self, nin):\n        self.w = [Value(random.uniform(-1,1)) for _ in range(nin)]\n        self.b = Value(random.uniform(-1,1))\n        \n        \n    def __call__(self, x):\n        # w * x + b\n        act = sum((wi*xi for wi,xi in zip(self.w, x)), self.b)\n        out = act.tanh()\n        return out\n    \n    def parameters(self):\n        return self.w + [self.b]\n    \n    \nclass Layer:\n    \n    def __init__(self, nin, nout):\n        self.neurons = [Neuron(nin) for _ in range(nout)]\n        \n    def __call__(self, x):\n        outs = [n(x) for n in self.neurons]\n        return outs[0] if len(outs) == 1 else outs\n    \n    def parameters(self):\n        return [p for neuron in self.neurons for p in neuron.parameters()]\n    \nclass MLP:\n    \n    def __init__(self, nin, nouts):\n        sz =[nin] + nouts\n        self.layers = [Layer(sz[i], sz[i+1]) for i in range(len(nouts))]\n        \n    def __call__(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x\n    \n    def parameters(self):\n        return [p for layer in self.layers for p in layer.parameters()]\n        \n    \n\nprint('success')","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:57:32.326186Z","iopub.execute_input":"2024-05-04T16:57:32.326536Z","iopub.status.idle":"2024-05-04T16:57:32.338568Z","shell.execute_reply.started":"2024-05-04T16:57:32.326509Z","shell.execute_reply":"2024-05-04T16:57:32.337348Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"success\n","output_type":"stream"}]},{"cell_type":"code","source":"x = [2.0, 3.0, -1.0]\nn = MLP(3, [4, 4, 1])\nn(x)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:57:44.934525Z","iopub.execute_input":"2024-05-04T16:57:44.934924Z","iopub.status.idle":"2024-05-04T16:57:44.943842Z","shell.execute_reply.started":"2024-05-04T16:57:44.934893Z","shell.execute_reply":"2024-05-04T16:57:44.942566Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Value(data=0.8076708781515928)"},"metadata":{}}]},{"cell_type":"code","source":"n.parameters()","metadata":{"execution":{"iopub.status.busy":"2024-05-04T15:49:13.162086Z","iopub.execute_input":"2024-05-04T15:49:13.162920Z","iopub.status.idle":"2024-05-04T15:49:13.171360Z","shell.execute_reply.started":"2024-05-04T15:49:13.162824Z","shell.execute_reply":"2024-05-04T15:49:13.170035Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[Value(data=0.22785139825439038),\n Value(data=-0.5141526564271883),\n Value(data=-0.4830769013355878),\n Value(data=-0.4074592710102689),\n Value(data=0.8385879616955285),\n Value(data=-0.40347322003331976),\n Value(data=0.9537683027995205),\n Value(data=0.5278162271747115),\n Value(data=-0.07692842558711543),\n Value(data=0.7239665045035384),\n Value(data=-0.5940669132170848),\n Value(data=0.37315243650139096),\n Value(data=0.06355964921567425),\n Value(data=-0.8958566437465947),\n Value(data=-0.33179908136011527),\n Value(data=0.8738366072980717),\n Value(data=-0.48584988666252715),\n Value(data=0.815700044255427),\n Value(data=-0.1449936361991273),\n Value(data=-0.436241982818101),\n Value(data=0.39010844934569255),\n Value(data=-0.5997206180964183),\n Value(data=-0.7327926699198315),\n Value(data=0.781645735867621),\n Value(data=0.49940069095989936),\n Value(data=0.8051376901375569),\n Value(data=0.17949088035593275),\n Value(data=0.08338451269464842),\n Value(data=-0.8684776446094757),\n Value(data=0.38480836149947284),\n Value(data=0.6148139121446383),\n Value(data=-0.7861324893985342),\n Value(data=-0.3185094718178554),\n Value(data=0.8882952727298739),\n Value(data=0.7970118311076309),\n Value(data=0.6331919421868439),\n Value(data=-0.03043056401145572),\n Value(data=0.8377138684242194),\n Value(data=-0.1647600067102306),\n Value(data=0.713267061986198),\n Value(data=0.5345101556639555)]"},"metadata":{}}]},{"cell_type":"code","source":"len(n.parameters())","metadata":{"execution":{"iopub.status.busy":"2024-05-04T13:04:36.009176Z","iopub.execute_input":"2024-05-04T13:04:36.010317Z","iopub.status.idle":"2024-05-04T13:04:36.017159Z","shell.execute_reply.started":"2024-05-04T13:04:36.010276Z","shell.execute_reply":"2024-05-04T13:04:36.015952Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"41"},"metadata":{}}]},{"cell_type":"code","source":"draw_dot(n(x))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"xs = [\n    [2.0, 3.0, -1.0],\n    [3.0, -1.0, 0.5],\n    [0.5, 1.0, 1.0],\n    [1.0, 1.0, -1.0],\n]\nys = [1.0, -1.0, -1.0, 1.0] # desired targets","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:57:39.288013Z","iopub.execute_input":"2024-05-04T16:57:39.288837Z","iopub.status.idle":"2024-05-04T16:57:39.293855Z","shell.execute_reply.started":"2024-05-04T16:57:39.288799Z","shell.execute_reply":"2024-05-04T16:57:39.292828Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"## does not work without start argument to initilize summing with Value object set to zero\n\nfor k in range(20):\n    \n    # forward pass\n    ypred = [n(x) for x in xs]\n    loss = sum(((yout - ygt)**2 for ygt, yout in zip(ys, ypred)), start=Value(0))\n    \n    # backward pass\n    for p in n.parameters():\n        p.grad = 0.0\n    loss.backward()\n    \n    #update\n    for p in n.parameters():\n        p.data += -0.05 * p.grad\n        \n    print(k, loss.data)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:58:40.610931Z","iopub.execute_input":"2024-05-04T16:58:40.611331Z","iopub.status.idle":"2024-05-04T16:58:40.659144Z","shell.execute_reply.started":"2024-05-04T16:58:40.611299Z","shell.execute_reply":"2024-05-04T16:58:40.658000Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"0 0.042682512369833336\n1 0.039774498135288106\n2 0.037208627633266225\n3 0.03492992919683871\n4 0.032894365557668274\n5 0.03106628280931118\n6 0.029416534064838323\n7 0.02792108018853014\n8 0.026559933011818485\n9 0.025316347860440683\n10 0.02417619991257993\n11 0.02312749772461157\n12 0.022160000238832824\n13 0.021264912662884283\n14 0.020434643039182236\n15 0.01966260593146944\n16 0.018943062997002408\n17 0.018270992661034786\n18 0.01764198292169685\n19 0.01705214266617995\n","output_type":"stream"}]},{"cell_type":"code","source":"ypred","metadata":{"execution":{"iopub.status.busy":"2024-05-04T16:58:46.701688Z","iopub.execute_input":"2024-05-04T16:58:46.702071Z","iopub.status.idle":"2024-05-04T16:58:46.709118Z","shell.execute_reply.started":"2024-05-04T16:58:46.702043Z","shell.execute_reply":"2024-05-04T16:58:46.707948Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[Value(data=0.9461627026081698),\n Value(data=-0.9599160983705597),\n Value(data=-0.9235141104942557),\n Value(data=0.9181655475218413)]"},"metadata":{}}]},{"cell_type":"code","source":"##Forward pass\n## does not work without start argument to initilize summing with Value object set to zero\n#ypred = [n(x) for x in xs]\n#loss = sum(((yout - ygt)**2 for ygt, yout in zip(ys, ypred)), start=Value(0))\n\n#print('loss',loss)","metadata":{"execution":{"iopub.status.busy":"2024-05-04T15:52:17.501548Z","iopub.execute_input":"2024-05-04T15:52:17.502038Z","iopub.status.idle":"2024-05-04T15:52:17.511247Z","shell.execute_reply.started":"2024-05-04T15:52:17.501998Z","shell.execute_reply":"2024-05-04T15:52:17.509938Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"loss Value(data=5.044763282454489)\n","output_type":"stream"}]}]}